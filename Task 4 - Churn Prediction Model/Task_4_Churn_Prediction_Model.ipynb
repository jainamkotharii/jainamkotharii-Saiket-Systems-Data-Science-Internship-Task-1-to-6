{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Saiket System\n",
        "## Task 4 : Churn Prediction Model\n",
        "\n",
        "###Description:\n",
        "#### Choose suitable machine learning algorithms (e.g., logistic regression, decision trees) for churn prediction. Split data into training and testing sets, train and evaluate multiple models using metrics like accuracy, precision, recall, and F1-score. Perform feature selection and hyperparameter tuning for optimal performance"
      ],
      "metadata": {
        "id": "bmChq675xBpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")"
      ],
      "metadata": {
        "id": "mrLcxmFUzIdF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and Preprocess Data\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Telco_Customer_Churn_Dataset.csv\")\n",
        "\n",
        "# Fix TotalCharges (common issue in Telco dataset)\n",
        "df[\"TotalCharges\"] = df[\"TotalCharges\"].replace(\" \", np.nan)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].median())\n",
        "\n",
        "# Target variable\n",
        "y = df[\"Churn\"].map({\"No\": 0, \"Yes\": 1})\n",
        "\n",
        "# Drop ID and target from features\n",
        "X = df.drop([\"customerID\", \"Churn\"], axis=1)\n",
        "\n",
        "# One hot encode categorical features\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "print(\"Shape of features:\", X.shape)\n",
        "print(\"Shape of target:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnq_XW5m0JfZ",
        "outputId": "62e5786b-d61b-4c9d-f2ad-b78bf6441c11"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features: (7043, 30)\n",
            "Shape of target: (7043,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Train Test Split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIl1s32Y0RE3",
        "outputId": "b4e99c00-e16a-4c7c-863d-b9ac1adcd710"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (5634, 30)\n",
            "Test shape: (1409, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Feature Scaling\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "M0rURIGi0V0u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train Multiple Models\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "def evaluate_model(name, model, X_tr, X_te, y_tr, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "\n",
        "    acc = accuracy_score(y_te, y_pred)\n",
        "    prec = precision_score(y_te, y_pred)\n",
        "    rec = recall_score(y_te, y_pred)\n",
        "    f1 = f1_score(y_te, y_pred)\n",
        "\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print(\"Accuracy :\", round(acc, 4))\n",
        "    print(\"Precision:\", round(prec, 4))\n",
        "    print(\"Recall   :\", round(rec, 4))\n",
        "    print(\"F1-score :\", round(f1, 4))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_te, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, y_pred))\n",
        "\n",
        "    return model, acc, prec, rec, f1\n",
        "\n",
        "results = {}"
      ],
      "metadata": {
        "id": "HQTdjwGu0Y50"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression on scaled data\n",
        "lr_model, lr_acc, lr_prec, lr_rec, lr_f1 = evaluate_model(\n",
        "    \"Logistic Regression\",\n",
        "    models[\"Logistic Regression\"],\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test\n",
        ")\n",
        "results[\"Logistic Regression\"] = (lr_acc, lr_prec, lr_rec, lr_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXVlFnHR1PB2",
        "outputId": "0e8fa161-e891-442b-aece-0c499903d230"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Logistic Regression\n",
            "Accuracy : 0.807\n",
            "Precision: 0.6584\n",
            "Recall   : 0.5668\n",
            "F1-score : 0.6092\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87      1035\n",
            "           1       0.66      0.57      0.61       374\n",
            "\n",
            "    accuracy                           0.81      1409\n",
            "   macro avg       0.75      0.73      0.74      1409\n",
            "weighted avg       0.80      0.81      0.80      1409\n",
            "\n",
            "Confusion Matrix:\n",
            " [[925 110]\n",
            " [162 212]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree on original data\n",
        "dt_model, dt_acc, dt_prec, dt_rec, dt_f1 = evaluate_model(\n",
        "    \"Decision Tree\",\n",
        "    models[\"Decision Tree\"],\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test\n",
        ")\n",
        "results[\"Decision Tree\"] = (dt_acc, dt_prec, dt_rec, dt_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0tBrzWG1SPV",
        "outputId": "4eb1b018-d89e-4d69-a77f-d3d7e24fcbde"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Decision Tree\n",
            "Accuracy : 0.7417\n",
            "Precision: 0.5139\n",
            "Recall   : 0.4947\n",
            "F1-score : 0.5041\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.83      1035\n",
            "           1       0.51      0.49      0.50       374\n",
            "\n",
            "    accuracy                           0.74      1409\n",
            "   macro avg       0.67      0.66      0.66      1409\n",
            "weighted avg       0.74      0.74      0.74      1409\n",
            "\n",
            "Confusion Matrix:\n",
            " [[860 175]\n",
            " [189 185]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest on original data\n",
        "rf_model, rf_acc, rf_prec, rf_rec, rf_f1 = evaluate_model(\n",
        "    \"Random Forest\",\n",
        "    models[\"Random Forest\"],\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test\n",
        ")\n",
        "results[\"Random Forest\"] = (rf_acc, rf_prec, rf_rec, rf_f1)\n",
        "\n",
        "print(\"\\nSummary of model performance (Accuracy, Precision, Recall, F1):\")\n",
        "for name, metrics in results.items():\n",
        "    print(name, \":\", [round(m, 4) for m in metrics])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNEdzj2p1V0-",
        "outputId": "fbc5f396-5941-45f0-db66-a27e6d87acec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Random Forest\n",
            "Accuracy : 0.7864\n",
            "Precision: 0.6237\n",
            "Recall   : 0.492\n",
            "F1-score : 0.5501\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1035\n",
            "           1       0.62      0.49      0.55       374\n",
            "\n",
            "    accuracy                           0.79      1409\n",
            "   macro avg       0.73      0.69      0.71      1409\n",
            "weighted avg       0.77      0.79      0.78      1409\n",
            "\n",
            "Confusion Matrix:\n",
            " [[924 111]\n",
            " [190 184]]\n",
            "\n",
            "Summary of model performance (Accuracy, Precision, Recall, F1):\n",
            "Logistic Regression : [0.807, 0.6584, 0.5668, 0.6092]\n",
            "Decision Tree : [0.7417, 0.5139, 0.4947, 0.5041]\n",
            "Random Forest : [0.7864, 0.6237, 0.492, 0.5501]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Feature Importance (Random Forest)\n",
        "\n",
        "feature_importances = pd.Series(\n",
        "    rf_model.feature_importances_,\n",
        "    index=X_train.columns\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Important Features for Churn (Random Forest):\")\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU76stPi0d40",
        "outputId": "04a4d5c9-1cdc-4d92-cbc1-d9b3bae15f98"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Important Features for Churn (Random Forest):\n",
            "TotalCharges                      0.192096\n",
            "tenure                            0.174733\n",
            "MonthlyCharges                    0.168413\n",
            "PaymentMethod_Electronic check    0.038771\n",
            "InternetService_Fiber optic       0.038641\n",
            "Contract_Two year                 0.030176\n",
            "gender_Male                       0.028321\n",
            "OnlineSecurity_Yes                0.028191\n",
            "PaperlessBilling_Yes              0.025617\n",
            "Partner_Yes                       0.023326\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Hyperparameter Tuning (Random Forest)\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [None, 5, 10],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "    \"min_samples_leaf\": [1, 2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"f1\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest parameters from GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred_best = best_rf.predict(X_test)\n",
        "\n",
        "print(\"\\nPerformance of Tuned Random Forest:\")\n",
        "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred_best), 4))\n",
        "print(\"Precision:\", round(precision_score(y_test, y_pred_best), 4))\n",
        "print(\"Recall   :\", round(recall_score(y_test, y_pred_best), 4))\n",
        "print(\"F1-score :\", round(f1_score(y_test, y_pred_best), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMaeesrz0gRG",
        "outputId": "300942fd-b8ff-4c1c-bd35-4149dd0a9df5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters from GridSearchCV:\n",
            "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "\n",
            "Performance of Tuned Random Forest:\n",
            "Accuracy : 0.8034\n",
            "Precision: 0.6611\n",
            "Recall   : 0.5321\n",
            "F1-score : 0.5896\n"
          ]
        }
      ]
    }
  ]
}